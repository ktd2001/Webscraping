{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Database from Web Scraping Social Networking Website Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source Data: https://en.wikipedia.org/wiki/List_of_social_networking_websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports packages and data retrieval steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import requests# used for loading webpages for source code\n",
    "import urllib.request # used to open URLs \n",
    "import pandas as pd # to manipulated data\n",
    "import sqlite3 #deploy SQL database\n",
    "import lxml.html # Convert HTML text\n",
    "from bs4 import BeautifulSoup # HTML/XML parser for Python\n",
    "#pulling data out of HTML and XML\n",
    "# Beautiful Soup Documentation\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of social networking websites - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "url    = \"https://en.wikipedia.org/wiki/List_of_social_networking_websites\"\n",
    "source = urllib.request.urlopen(url)\n",
    "soup   = BeautifulSoup(source, 'lxml')\n",
    "title  = soup.title.text\n",
    "print(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate table data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table info\n",
    "info_table      = soup.find('table', class_='wikitable sortable')\n",
    "info_table_rows = info_table.find_all('tr')\n",
    "table           = soup.findAll('table')\n",
    "response        = requests.get(url)\n",
    "headers         = ([\"Name\", \"Description_focus\", \"Date_launched\",\n",
    "              \"Registered_users\", \"Registration\", \"Global_Alexa_page_ranking\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse table into a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of SNW:  187 \n",
      "\n",
      "First 5 rows from the data table:           Name                                  Description_focus  \\\n",
      "0     About.me                             Social networking site   \n",
      "1       aNobii                                              Books   \n",
      "2  AsianAvenue  A social network for the Asian American community   \n",
      "3  aSmallWorld        European jet set and social elite worldwide   \n",
      "4     Athlinks                                  Running, swimming   \n",
      "\n",
      "  Date_launched Registered_users Registration Global_Alexa_page_ranking  \n",
      "0  October 2009     5,000,000[3]         Open                      1447  \n",
      "1          2006              NaN         Open                 26,939[4]  \n",
      "2          1997              NaN         Open                170,384[5]  \n",
      "3    March 2004       550,000[6]  Invite-only                580,060[7]  \n",
      "4          2001       139,458[8]         Open                 69,170[9]   \n",
      "\n",
      "Table Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187 entries, 0 to 186\n",
      "Data columns (total 6 columns):\n",
      "Name                         187 non-null object\n",
      "Description_focus            187 non-null object\n",
      "Date_launched                128 non-null object\n",
      "Registered_users             125 non-null object\n",
      "Registration                 182 non-null object\n",
      "Global_Alexa_page_ranking    184 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 8.9+ KB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df         = pd.read_html(response.content, skiprows = 1)[0]\n",
    "df.columns = headers\n",
    "type(df) #pandas.core.frame.DataFrame\n",
    "print(\"Total number of SNW: \", len(df),'\\n')\n",
    "print(\"First 5 rows from the data table:\", df.head(5),'\\n')\n",
    "print(\"Table Information:\")\n",
    "print(df.info(),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Created SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the 1st output of my sqlite Database:\n",
      "==================================================\n",
      "Instagram is ('A photo and video sharing site owned by Facebook.',)\n",
      "\n",
      "==================================================\n",
      "This is the 2nd output of my sqlite Database:\n",
      "==================================================\n",
      "Instagram registered users total ('300,000,000[131]',)\n"
     ]
    }
   ],
   "source": [
    "#Make database and will only exist in memory\n",
    "db= sqlite3.connect(':memory:')#use the argument \":memory:\" to create a temporary database in the RAM\n",
    "cursor = db.cursor()# used to execute the social media query being made\n",
    "cursor.execute(\"\"\"\n",
    "  CREATE TABLE SOCIAL_MEDIA_WEBSITES(\"Name\", \"Description_focus\",\n",
    "                                     \"Date_launched\", \"Registered_users\",\n",
    "                                     \"Registration\", \"Global_Alexa_page_ranking\") \n",
    "\"\"\") # Create Database table\n",
    "\n",
    "#Inserting Data into the Database\n",
    "for row in df.itertuples():\n",
    "   insert_sql_syntax = \"\"\"\n",
    "   INSERT INTO SOCIAL_MEDIA_WEBSITES(\"Name\", \"Description_focus\",\n",
    "                                     \"Date_launched\", \"Registered_users\",\n",
    "                                     \"Registration\", \"Global_Alexa_page_ranking\")\n",
    "              VALUES (?,?,?,?,?,?)\n",
    "              \"\"\"\n",
    "   cursor.execute(insert_sql_syntax, row[1:])\n",
    "db.commit()\n",
    "## extract info from db\n",
    "for row in cursor.execute(\"\"\"\n",
    "  SELECT Description_focus\n",
    "  FROM SOCIAL_MEDIA_WEBSITES\n",
    "  WHERE Name = \"Instagram\"\n",
    "\"\"\"):\n",
    "  print('This is the 1st output of my sqlite Database:\\n==================================================')\n",
    "print('Instagram is', row)  \n",
    "\n",
    "print('\\n==================================================')\n",
    "\n",
    "for row in cursor.execute(\"\"\"\n",
    "    SELECT Registered_users\n",
    "    FROM SOCIAL_MEDIA_WEBSITES\n",
    "    WHERE Name = \"Instagram\"\n",
    "\"\"\"):\n",
    "    print('This is the 2nd output of my sqlite Database:\\n==================================================')\n",
    "print('Instagram registered users total', row)\n",
    "\n",
    "\n",
    "# Pulling in the data from my database to create graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '5000000[3]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d3f29e77e20a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mgraph_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-d3f29e77e20a>\u001b[0m in \u001b[0;36mgraph_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print(row[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mRegistered_users\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mGlobal_Alexa_page_ranking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '5000000[3]'"
     ]
    }
   ],
   "source": [
    "def graph_data():\n",
    "    cursor.execute(\"\"\"\n",
    "  SELECT Name, \n",
    "  Registered_users, \n",
    "  Global_Alexa_page_ranking \n",
    "  FROM SOCIAL_MEDIA_WEBSITES \n",
    "\"\"\")\n",
    "    \n",
    "\n",
    "    Name                        = []\n",
    "    Registered_users            = []\n",
    "    Global_Alexa_page_ranking   = []\n",
    "\n",
    "\n",
    "    for row in cursor.fetchall():\n",
    "        #print(row[0])\n",
    "        Name.append(row[0])\n",
    "        Registered_users.append(int(row[1].replace(',', '').strip()))\n",
    "        Global_Alexa_page_ranking.append(int(row[2].replace(',','').strip()))\n",
    "\n",
    "\n",
    "graph_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '5000000[3]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3b99cedca8f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mRegistered_users\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mGlobal_Alexa_page_ranking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '5000000[3]'"
     ]
    }
   ],
   "source": [
    "# Pulling in the data from my database\n",
    "cursor.execute(\"\"\"\n",
    "  SELECT Name, Registered_users, Global_Alexa_page_ranking FROM SOCIAL_MEDIA_WEBSITES \n",
    "\"\"\")\n",
    "\n",
    "Name                        = []\n",
    "Registered_users            = []\n",
    "Global_Alexa_page_ranking   = []\n",
    "\n",
    "\n",
    "for row in cursor.fetchall():\n",
    "    Name.append(row[0])\n",
    "    Registered_users.append(int(row[1].replace(',', '').strip()))\n",
    "    Global_Alexa_page_ranking.append(int(row[2].replace(',','').strip()))\n",
    "    \n",
    "\n",
    "# Creating a dataframe out of all the rows from database\n",
    "plot1 = {\n",
    "    'Name':    [],\n",
    "    'Registered_users':   [],\n",
    "    'Global_Alexa_page_ranking':    []   \n",
    "}\n",
    "for row in Name:\n",
    "    plot1['Name'].append(row)\n",
    "for row in Users:\n",
    "    plot1['Registered_users'].append(row)\n",
    "for row in Rank:\n",
    "    plot1['Global_Alexa_page_ranking'].append(row)\n",
    "df1 = pd.DataFrame(plot1)\n",
    "\n",
    "df1.iloc[180,0] = 'Social Users'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '5000000[3]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3da8d77621e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mRegistered_users\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mGlobal_Alexa_page_ranking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '5000000[3]'"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "    SELECT Name, Registered_users, Global_Alexa_page_ranking FROM SOCIAL_MEDIA_WEBSITES \n",
    "\"\"\")\n",
    "\n",
    "Name                        = []\n",
    "Registered_users            = []\n",
    "Global_Alexa_page_ranking   = []\n",
    "\n",
    "\n",
    "for row in cursor.fetchall():\n",
    "    Name.append(row[0])\n",
    "    Registered_users.append(int(row[1].replace(',', '').strip()))\n",
    "    Global_Alexa_page_ranking.append(int(row[2].replace(',','').strip()))\n",
    "print(row,'\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pulling in a seperate file for Monthly Active User merging the dataframes to plot\n",
    "rr = requests.get('https://www.dreamgrow.com/top-15-most-popular-social-networking-sites/')\n",
    "\n",
    "htmltext = lh.fromstring(rr.text)\n",
    "\n",
    "#table info\n",
    "gdp = htmltext.get_element('table') \n",
    "\n",
    "gdpbody = gdp[1].getchildren()\n",
    "\n",
    "plot2 = {\n",
    "    'Name' : [],\n",
    "    'Monthly Active Users'     : []\n",
    "}\n",
    "for i in gdpbody:\n",
    "        plot2['Name'].append(i.getchildren()[0].text_content())\n",
    "        plot2['Monthly Active Users'].append(float(i.getchildren()[1].text_content().replace(',','').strip()))\n",
    "\n",
    "df2=pd.DataFrame(plot2)\n",
    "\n",
    "df3 = pd.merge(df1, df2, left_on = 'Social Network', right_on = 'Social Network')\n",
    "\n",
    "df3['Inactive_Users'] = (df3['Monthly Active Users']*1000000000) /df3['Users']\n",
    "#Mutiplied GDP by 1B since it is represented in billions\n",
    "\n",
    "df4 = df3.copy()\n",
    "\n",
    "# Creating sizes and texts  for my plot\n",
    "hover_text = []\n",
    "bubble_size = []\n",
    "bubble_ref =[]\n",
    "\n",
    "for index, row in df3.iterrows():\n",
    "    hover_text.append(('Social Network: {Social Network}<br>'+\n",
    "                      'Monthly Active Users : {Monthly Active Users}<br>'+\n",
    "                      'Users : {Users}<br>'+\n",
    "                      'Inactive_Users : {Inactive_Users}<br>').format(Social_Network=row['Social Network'],\n",
    "                                                             Users = row['Users'],\n",
    "                                                             Monthly_Active_User = row['Monthly Active User'],\n",
    "                                                             UserPer = row['Inactive_Users']\n",
    "                                                                                                ))\n",
    "    bubble_size.append(row['Users'])\n",
    "    bubble_ref.append(math.sqrt(row['Users']))\n",
    "\n",
    "\n",
    "df3['text']= hover_text\n",
    "df3['size'] = bubble_size\n",
    "df3['ref']=bubble_ref\n",
    "sizeref = (max(df3['ref']))/350\n",
    "\n",
    "#close database\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
