{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Database from Web Scraping Social Networking Website and SQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source Data: https://en.wikipedia.org/wiki/List_of_social_networking_websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports packages and data retrieval steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import requests# used for loading webpages for source code\n",
    "import urllib.request # used to open URLs \n",
    "import pandas as pd # to manipulated data\n",
    "import sqlite3 #deploy SQL database\n",
    "import lxml.html # Convert HTML text\n",
    "from bs4 import BeautifulSoup # HTML/XML parser for Python\n",
    "#pulling data out of HTML and XML\n",
    "# Beautiful Soup Documentation\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of social networking websites - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "url    = \"https://en.wikipedia.org/wiki/List_of_social_networking_websites\"\n",
    "#url    = \"https://www.dreamgrow.com/top-15-most-popular-social-networking-sites/\"\n",
    "source = urllib.request.urlopen(url)\n",
    "soup   = BeautifulSoup(source, 'lxml')\n",
    "title  = soup.title.text\n",
    "print(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate table data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table info\n",
    "info_table      = soup.find('table', class_='wikitable sortable')\n",
    "info_table_rows = info_table.find_all('tr')\n",
    "all_tables      = soup.findAll('table')\n",
    "response        = requests.get(url)\n",
    "headers         = ([\"Name\", \"Description_focus\", \"Date_launched\",\n",
    "              \"Registered_users\", \"Registration\", \"Global_Alexa_page_ranking\"])\n",
    "#print(all_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Registered user to a string data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Registered_users = []\n",
    "str = \"\"\n",
    "for Registered_user in Registered_users:\n",
    "    info= Registered_users.text\n",
    "    str+=info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b16feb8ead8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistered_users\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.Registered_users.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse table into a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df         = pd.read_html(response.content, skiprows = 1)[0]\n",
    "df.columns = headers\n",
    "type(df) #pandas.core.frame.DataFrame\n",
    "print(\"Total number of SNW: \", len(df),'\\n')\n",
    "print(\"First 5 rows from the data table:\", df.head(5),'\\n')\n",
    "print(\"Table Information:\")\n",
    "print(df.info(),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Created SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make database and will only exist in memory\n",
    "db= sqlite3.connect(':memory:')#use the argument \":memory:\" to create a temporary database in the RAM\n",
    "cursor = db.cursor()# used to execute the social media query being made\n",
    "cursor.execute(\"\"\"\n",
    "  CREATE TABLE SOCIAL_MEDIA_WEBSITES(\"Name\", \"Description_focus\",\n",
    "                                     \"Date_launched\", \"Registered_users\",\n",
    "                                     \"Registration\", \"Global_Alexa_page_ranking\") \n",
    "\"\"\") # Create Database table\n",
    "\n",
    "#Inserting Data into the Database\n",
    "for row in df.itertuples():\n",
    "   insert_sql_syntax = \"\"\"\n",
    "   INSERT INTO SOCIAL_MEDIA_WEBSITES(\"Name\", \"Description_focus\",\n",
    "                                     \"Date_launched\", \"Registered_users\",\n",
    "                                     \"Registration\", \"Global_Alexa_page_ranking\")\n",
    "              VALUES (?,?,?,?,?,?)\n",
    "              \"\"\"\n",
    "   cursor.execute(insert_sql_syntax, row[1:])\n",
    "db.commit()\n",
    "## extract info from db\n",
    "for row in cursor.execute(\"\"\"\n",
    "  SELECT Description_focus\n",
    "  FROM SOCIAL_MEDIA_WEBSITES\n",
    "  WHERE Name = \"Instagram\"\n",
    "\"\"\"):\n",
    "  print('This is the 1st output of my sqlite Database:\\n==================================================')\n",
    "print('Instagram is', row)  \n",
    "\n",
    "print('\\n==================================================')\n",
    "\n",
    "for row in cursor.execute(\"\"\"\n",
    "    SELECT Registered_users\n",
    "    FROM SOCIAL_MEDIA_WEBSITES\n",
    "    WHERE Name = \"Instagram\"\n",
    "\"\"\"):\n",
    "    print('This is the 2nd output of my sqlite Database:\\n==================================================')\n",
    "print('Instagram registered users total', row)\n",
    "\n",
    "\n",
    "# Pulling in the data from my database to create graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} observations and {} features in this dataset. \\n\".format(df.shape[0],df.shape[1]))\n",
    "\n",
    "print(\"There are {} types of social networking sites in this dataset such as {}... \\n\".format(len(df.Description_focus.unique()),\n",
    "                                                                           \", \".join(df.Description_focus.unique()[0:5])))\n",
    "\n",
    "print(\"There are {} registered users on social networking sites in this dataset such as {}... \\n\".format(len(df.Registered_users.unique()),\n",
    "                                                                                                             \", \".join(df.Registered_users.unique()[0:5])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_data():\n",
    "    cursor.execute(\"\"\"\n",
    "  SELECT Name, \n",
    "  Registered_users, \n",
    "  Global_Alexa_page_ranking \n",
    "  FROM SOCIAL_MEDIA_WEBSITES \n",
    "\"\"\")\n",
    "    \n",
    "\n",
    "    Name                        = []\n",
    "    Registered_users            = []\n",
    "    Global_Alexa_page_ranking   = []\n",
    "\n",
    "\n",
    "    for row in cursor.fetchall():\n",
    "        #print(row[0])\n",
    "        Name.append(row[0])\n",
    "        Registered_users.append(int(row[1].replace(',', '').strip(), base=16))\n",
    "        Global_Alexa_page_ranking.append(str(row[2].replace(',','').strip(), base=16))\n",
    "\n",
    "# calling graph function \n",
    "graph_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling in the data from my database\n",
    "cursor.execute(\"\"\"\n",
    "  SELECT Name, Registered_users, Global_Alexa_page_ranking FROM SOCIAL_MEDIA_WEBSITES \n",
    "\"\"\")\n",
    "\n",
    "Name                        = []\n",
    "Registered_users            = []\n",
    "Global_Alexa_page_ranking   = []\n",
    "\n",
    "\n",
    "for row in cursor.fetchall():\n",
    "    Name.append(row[0])\n",
    "    Registered_users.append(int(row[1].replace(',', '').strip()))\n",
    "    Global_Alexa_page_ranking.append(int(row[2].replace(',','').strip()))\n",
    "    \n",
    "\n",
    "# Creating a dataframe out of all the rows from database\n",
    "plot1 = {\n",
    "    'Name':    [],\n",
    "    'Registered_users':   [],\n",
    "    'Global_Alexa_page_ranking':    []   \n",
    "}\n",
    "for row in Name:\n",
    "    plot1['Name'].append(row)\n",
    "for row in Users:\n",
    "    plot1['Registered_users'].append(row)\n",
    "for row in Rank:\n",
    "    plot1['Global_Alexa_page_ranking'].append(row)\n",
    "df1 = pd.DataFrame(plot1)\n",
    "\n",
    "df1.iloc[180,0] = 'Social Users'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "    SELECT Name, Registered_users, Global_Alexa_page_ranking FROM SOCIAL_MEDIA_WEBSITES \n",
    "\"\"\")\n",
    "\n",
    "Name                        = []\n",
    "Registered_users            = []\n",
    "Global_Alexa_page_ranking   = []\n",
    "\n",
    "\n",
    "for row in cursor.fetchall():\n",
    "    Name.append(row[0])\n",
    "    Registered_users.append(int(row[1].replace(',', '').strip()))\n",
    "    Global_Alexa_page_ranking.append(int(row[2].replace(',','').strip()))\n",
    "print(row,'\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pulling in a seperate file for Monthly Active User merging the dataframes to plot\n",
    "rr = requests.get('https://www.dreamgrow.com/top-15-most-popular-social-networking-sites/')\n",
    "\n",
    "htmltext = lh.fromstring(rr.text)\n",
    "\n",
    "#table info\n",
    "gdp = htmltext.get_element('table') \n",
    "\n",
    "gdpbody = gdp[1].getchildren()\n",
    "\n",
    "plot2 = {\n",
    "    'Name' : [],\n",
    "    'Monthly Active Users'     : []\n",
    "}\n",
    "for i in gdpbody:\n",
    "        plot2['Name'].append(i.getchildren()[0].text_content())\n",
    "        plot2['Monthly Active Users'].append(float(i.getchildren()[1].text_content().replace(',','').strip()))\n",
    "\n",
    "df2=pd.DataFrame(plot2)\n",
    "\n",
    "df3 = pd.merge(df1, df2, left_on = 'Social Network', right_on = 'Social Network')\n",
    "\n",
    "df3['Inactive_Users'] = (df3['Monthly Active Users']*1000000000) /df3['Users']\n",
    "#Mutiplied GDP by 1B since it is represented in billions\n",
    "\n",
    "df4 = df3.copy()\n",
    "\n",
    "# Creating sizes and texts  for my plot\n",
    "hover_text = []\n",
    "bubble_size = []\n",
    "bubble_ref =[]\n",
    "\n",
    "for index, row in df3.iterrows():\n",
    "    hover_text.append(('Social Network: {Social Network}<br>'+\n",
    "                      'Monthly Active Users : {Monthly Active Users}<br>'+\n",
    "                      'Users : {Users}<br>'+\n",
    "                      'Inactive_Users : {Inactive_Users}<br>').format(Social_Network=row['Social Network'],\n",
    "                                                             Users = row['Users'],\n",
    "                                                             Monthly_Active_User = row['Monthly Active User'],\n",
    "                                                             UserPer = row['Inactive_Users']\n",
    "                                                                                                ))\n",
    "    bubble_size.append(row['Users'])\n",
    "    bubble_ref.append(math.sqrt(row['Users']))\n",
    "\n",
    "\n",
    "df3['text']= hover_text\n",
    "df3['size'] = bubble_size\n",
    "df3['ref']=bubble_ref\n",
    "sizeref = (max(df3['ref']))/350\n",
    "\n",
    "#close database\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
